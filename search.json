[
  {
    "objectID": "posts/ai-strategy-series/2-business-applicability-digital-transform/index.html",
    "href": "posts/ai-strategy-series/2-business-applicability-digital-transform/index.html",
    "title": "2. AI is Here, But its Business-Applicability may not be Obvious",
    "section": "",
    "text": "Key Takeaway\n\n\n\nEven if a business has a highly-capable IT function, it may only have a handful of specialists experimenting with AI technologies. How do you scale that? Even if you have built valuable AI-driven prototypes (or are even in-production), getting customers or business users to adopt that solution as part of their day-to-day activities is often the biggest challenge.\nEven if you have managed to attract and retain many data-science types within your business, real bandwidth to embed AI within the organisation will only come with training those non-technical employees and reskilling them to leverage these new class of tools such as agentic-AI."
  },
  {
    "objectID": "posts/ai-strategy-series/2-business-applicability-digital-transform/index.html#footnotes",
    "href": "posts/ai-strategy-series/2-business-applicability-digital-transform/index.html#footnotes",
    "title": "2. AI is Here, But its Business-Applicability may not be Obvious",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nData Engineering with AWS, Gareth Eagar, Packt Publishing, 2nd Ed. October 2023↩︎\nMachine Learning vs. AI: Differences, Uses, and Benefits, Coursera Staff, January 2025↩︎\nOpportunities in AI, DeepLearning.AI / Stanford Andrew Ng’s Assessment of Growth (shaded part) in different fields of AI, July 2023↩︎\n16 Changes to the Way Enterprises Are Building and Buying Generative AI, by Sarah Wang and Shangda Xu, March 2024↩︎\nRewired, The McKinsey Guide to Outcompeting in the Age of Digital and AI, Wiley, June 2023.↩︎\nBeyond Performance 2.0, A Proven Approach to Leading Large-Scale Change, 2nd Ed., Wiley, July 2019.↩︎\nChapter 3: Have business leaders define what’s possible, Rewired, Wiley, June 2023↩︎\nChapter 3: Have business leaders define what’s possible, Rewired, Wiley, June 2023↩︎\nPractitioners Perspectives: GenAI Risks and Opportunities, Georgian.io, 2023↩︎\nGenerative AI Making Waves, Adoption waves in banking and capital markets, Celent, AWS, May 2024.↩︎\nChapter 1: Performance and Health, Beyond Performance 2.0, 2nd Ed., Wiley, July 2019↩︎\nSetting up Machine Learning projects for success A tried-and-tested guide to framing data science projects, Chris Hughes, May 2021↩︎\nIntroduction to Research Data Science developed by, The Alan Turing Institute, Research Engineering Group↩︎"
  },
  {
    "objectID": "posts/ai-strategy-series/1-overview/index.html",
    "href": "posts/ai-strategy-series/1-overview/index.html",
    "title": "1. Framing an AI Strategy: Where Do You Start?",
    "section": "",
    "text": "Key Takeaway\n\n\n\nEven if the term AI is flawed for its imprecision, the shift in thinking that it has unleashed, in terms of acknowledging digitalisation as table stakes for having a competitive edge in any business, upon which to layer these emerging technologies, can’t be disputed.\nIt’s still early for the adoption of a strategy around AI, one that is initially explorative. Since advancements in this field are currently so rapid, no business can fully know how this will shape their future product or service, but to dismiss this as hype and not engage, would be a fatal error, in my opinion."
  },
  {
    "objectID": "posts/ai-strategy-series/1-overview/index.html#forming-a-strategy-around-machine-learning-ai",
    "href": "posts/ai-strategy-series/1-overview/index.html#forming-a-strategy-around-machine-learning-ai",
    "title": "1. Framing an AI Strategy: Where Do You Start?",
    "section": "Forming a Strategy around Machine Learning / AI",
    "text": "Forming a Strategy around Machine Learning / AI\nIf you were to believe the hype, every business executive these days is ‘doing’ AI. It has become a byword for sophistication in every product or service we might want. AI has become a veneer for everything - irrespective of whether a process involving the usage of artificial-intelligence was actually invoked in the production of a given product or the provision of a given service.\nThe MAD (ML, AI & Data) Landscape1 produced by venture capital firm Firstmark, is considered a key annual survey of the AI ecosystem. Solutions tackling every niche are battling out for what Gartner forecast2 to be a $300bn market for AI developer tools within three years. As a business setting out on an AI journey, where are you supposed to start?\nWhile there has been a degree of hype around Large Language Models (LLMs), unleashed by OpenAI’s release of ChatGPT onto the market in late 2022, the effect has been to shine light on the value that can be derived from a more rigorous approach to machine learning and AI, especially one that is knitted into the fabric and culture of a business.\n\nWhere do you start?\n\n\nFor a complex problem, one is often advised to break it down into a series of smaller problems, solving these iteratively. As an analogy, if the objective is to become a great artist, when you’ve never in fact held a paint brush, then a starting point might be a colour-by-numbers approach. Remember those?\nNot to over-trivialise the challenge of implementing a solid AI strategy, this series is my own colour-by-numbers attempt to assemble some ideas around important aspects of machine learning that I think are relevant to any business looking to become involved in this field. Having had a background in finance, with an emphasis on research, I’ve been an early convert to data-science in my career and its many, mostly open-source, tools. These same tools, in turn, have been assembled into a rich ecosystem of developer tools to tackle machine learning. But there can be an overwhelming number of them to master, so much so that one can get bogged-down in what technology stack to form, rather than looking beyond the technology and solving for the business use-cases. Having a sketch of a route to the AI higher-ground, much like having a picture we can colour, is better than having none at all.\n\n\n\n\n\n\n\n\nBring everyone on this journey\nTo do machine learning well within an organisation requires that it is done methodically and iteratively at scale, a practice known as machine-learning operations, or MLOps for short. I’ve married my interest in platform-engineering more generally with this field and I think its methodologies can be transformative for companies.\nI’m firmly of the belief that, although technical, most of these technologies don’t require you to be a data-scientist, per se, or even a software engineer. The scarcity of these professionals shouldn’t prevent an organisation from embracing these ideas and running with them.\nIn fact, they are the professionals involved in the day-to-day business of financing, investing-in and operating the disparate businesses, that are the ones that will have the ideas for how things can be done differently, aided by AI, so it makes sense that they are also the ones that have a sense for what is viable, technologically-speaking, too - and develop the requisite skills to be able to build prototypes more easily.\nBottom line — there needs to be a plan in place to educate people on these emerging technologies, since their future jobs will almost certainly entail leveraging them.\n\n\nStage your adoption\nWhile it was offered in the context of working with Large Language Models (LLMs), Georgian’s ‘Crawl-Walk-Run’ analogy (below left) applies more generally to an approach to AI adoption that can be calibrated to an organisation’s overall level of sophistication with these technologies. It’s acknowledged that there should be a staged approach towards adopting AI and adapting a business to then leverage AI. As a slightly more formal categorisation, the MLOps Maturity Model (below right) from AWS is appealing for its articulation around a phased approach to working with Machine Learning / AI:\n\nInitial phase — a secure experimentation environment, data-enabled, for internal users to build proof-of-concepts around solving a specific business problem with ML. AWS present their Sagemaker solution, but this could just as easily be a self-hosted JupyterHub, with connections into S3-hosted data assets, allowing users to collaborate on Jupyter notebooks.\nRepeatable phase — this typically involves productionising what has proved effective as a PoC in the phase above. Code in notebooks get formalised as more robust pipelines, split-out typically as feature, training and inference. In conjunction, code repository structures are formalised as are data repository (S3 bucket) structures, for containing models and model-artifacts. This approach supports complete auditability of every experimentation. An AWS sample environment with these structures, deployable via CDK is available at aws-samples/aws-enterprise-mlops-framework. I will discuss other lighter-touch MLOps solutions like Modal in part three of this blog-series.\nReliable phase — even though the models have been generated via the ML pipelines, they need to be tested before they get promoted to production. An automatic testing methodology is introduced, for both the model and triggering infrastructure, in an isolated staging (pre-production) environment that simulates production.\nScalable phase — after the productionisation of the first ML solution, scaling of the MLOps foundation to support multiple data science teams to collaborate and productionize tens or hundreds of ML use cases is necessary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Georgian - Stages of LLM Adoption3\n\n\n\n\n\n\n\n\n\n\n\n(b) AWS - MLOps Maturity Model4\n\n\n\n\n\n\n\nFigure 1: Ramping to Different Levels of ML/AI Sophistication Happens in Stages\n\n\n\n\n\n\nDocumentation as a Framing Mechanism\nThe landscape around AI/ML is evolving rapidly. There are new terminologies, new technology categories - a seemingly unending stream of solutions to problems we didn’t even know we had. As with most things, it can be helpful to break them down into smaller addressable parts and to acknowledge who your end audience is. That’s what I try to do with the documentation hierarchy, presented below, which I find helpful when engaging with clients. Levels 1 through 5 differ in terms of technical detail, tackling high-level concepts for business at the top and delving into technical implementation detail for technologists towards the bottom. Spanning horizontally are the delineated components of a MLOps value-chain. Think of the elements in Level 2 as the assets one draws on when evolving a machine-learning capability, while Level 3 are the processes undertaken (think in terms of a continuous life-cycle or fly-wheel) that sweat those assets for the delivery of business value-add.\n\n\n\n\nHigh-Level Conceptual Docs - answering questions like, what problems are we trying to solve with ML/AI?, do these technologies open new markets for our business? if we don’t respond, can competitors leap-frog our position technologically?\nML/AI Value-chain - this is our approach to breaking-down the various components that come together to form a system for implementing ML/AI solutions.\nMLOps Processes Lifecycle - there are many varied MLOps-process lifecycle frameworks in the wild. We have found this particular model from Google’s Practitioners Guide to MLOps5 to be more instructive than others.\nProof of Concepts - these are proof-of-concepts involving combining different technology stacks and solutions either within a delineated part of the value-chain or across multiple parts.\nProjects / Implementations - these are short project descriptions that depict approaches to encapsulating business processes as self-contained pipelines or where technologies are bundled as app-sets to solve particular business requirements.\n\n\n\n\n\n\n\n\n\nFigure 2: Analect Documentation Hierarchy — Using documentation to frame a plan for working with AI\n\n\n\n\n\n\nThis documentation hierarchy could also form as a framework for planning an AI strategy within an organisation. Level 1 is where high-level corporate aspirations can be set for what transformations are envisaged with these new technologies. Planning around building machine-learning operational capabilities and processes can be formed in Levels 2 and 3, respectively. Then proof-of-concepts (Level 4) involving different coupling of technologies can be explored followed by actual project MVPs (minimum-viable-products) (Level 5), which have been prioritised for implementation at the higher levels. Based on feedback and learnings from these early implementations, project-planning and prioritisations at Level 1 will adjust accordingly, perhaps elevating certain successful MVPs to more widely-scoped production-ready implementations.\n\n\nWhat I plan to cover in this blog series\nThis blog series will reference technological approaches, but it won’t be drilling down into the technical details of these. I’ll aim to cover those off in a later blog-series. Below you’ll find a map of what we’ll be covering. There’s enough material and opinions out there to fill a book on each, no doubt, but sometimes it’s better to get started with a simple approach and refine to your own business’ unique needs.\n\n\n\nNext up #2. AI is Here, But its Business-Applicability may not be Obvious."
  },
  {
    "objectID": "posts/ai-strategy-series/1-overview/index.html#footnotes",
    "href": "posts/ai-strategy-series/1-overview/index.html#footnotes",
    "title": "1. Framing an AI Strategy: Where Do You Start?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 2024 MAD contains over 2000 individual tools, up more than 40% on 2023. Is it any wonder that most feel overwhelmed.↩︎\nGartner predicts AI software will grow to $297 billion by 2027.↩︎\nIntroducing Georgian’s ‘Call, Walk, Run’ Framework for Adopting Generative AI, by Ben Wilde, Eli Scott and Royal Sequeira, 2023↩︎\nMLOps foundation roadmap for enterprises with Amazon SageMaker, by Sokratis Kartakis, Giuseppe Angelo Porcelli, Georgios Schinas and Shelbee Eigenbrode, June 2022↩︎\nPractitioners Guide to MLOps:, A framework for continuous delivery and automation of machine learning, Google White paper, May 2021↩︎"
  },
  {
    "objectID": "posts/ai-strategy-series/3-gitops-platforms-to-mlops/index.html",
    "href": "posts/ai-strategy-series/3-gitops-platforms-to-mlops/index.html",
    "title": "3. Platform Engineering for Evolving AI / ML Solutions",
    "section": "",
    "text": "Key Takeaway\n\n\n\nTo do machine-learning well requires rigour. Models trained on data are only as good as the data they are trained on and that data is changing, rendering older models useless. That’s where platforms come in. They contain the foundational blocks on which the process of MLOps gets performed. Clearly platform usage extends beyond machine-learning, but let’s view them in this more confined context here.\nPlatforms work well when they help automate processes and when the feedback loop for those developing solutions is fast, requiring the underlying compute infrastructure to be fast. This is what is commonly referred to as the fly-wheel effect, enabling value-creation."
  },
  {
    "objectID": "posts/ai-strategy-series/3-gitops-platforms-to-mlops/index.html#footnotes",
    "href": "posts/ai-strategy-series/3-gitops-platforms-to-mlops/index.html#footnotes",
    "title": "3. Platform Engineering for Evolving AI / ML Solutions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBackstage, An open source framework for building developer portals.↩︎\nMachine Learning Operations (MLOps): Overview, Definition, and Architecture, Kreuzberger, Kuhl, and Hirschl, KIT and IBM, 2022↩︎\nMLOps Landscape in 2024: Top Tools and Platforms, Stephen Oladele, September 2024↩︎\nderived from: MLOps: Emerging Trends in Data, Code, and Infrastructure, Venture Capital and Startup Perspective, June 2022↩︎\nK8s Is Not the Platform – Or Is It and We All Misunderstood?, Stefan Schimanski, Upbound, Nov. 2023↩︎\nSunrise: Zalando’s developer platform based on Backstage, Lessons learned from adopting Backstage as Developer Platform at Zalando, Aug. 2023↩︎\nMLOps Landscape in 2024: Top Tools and Platforms, Stephen Oladele, September 2024↩︎\nZenML v. Flyte v. Metaflow, Ankur Tyagi, January 2025↩︎\nMLOps on Modal, Charles Frye presenting on training an SLM using Modal↩︎\nOrchestrating Flexible Compute for ML with Dagster and Modal, with discussion of Function.starmap() to run multiple parallel workloads↩︎\nPractitioners guide to MLOps:, A framework for continuous delivery and automation of machine learning, Google, May 2021↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Colum McCoole",
    "section": "",
    "text": "I have been working at the intersection of finance and technology most of my career. My roles in finance were research-based and involved leveraging technology which motivated me to deepen my technical knowledge around software development and data-engineering by forming my own start-up and consulting firm, Analect, in 2012.\nLately, my focus has been on cloud-based platform engineering for machine-learning use-cases (MLOps), including LLMs (Generative AI), enabling the life-cycle of model development from data-acquisition through to model-training and selection and on-going auditing for business relevance and regulatory purposes. Given a dearth of data-scientists, business-users themselves can and should be enabled to experiment and work with these technologies with the right foundational platform tooling and guard-rails in place. My passion is to help create the know-how and culture for that vision to be realised.\n\nCertification\n\n\nAWS Solutions Architect – Professional\ndlt ELT Specialist\n\n\n\n\n\n\n\n\n\n\nPersonal life\nWhen not working, you’ll find me walking our Red Setter or sailing in Dublin Bay, both competitively and for pleasure."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analect",
    "section": "",
    "text": "On Developing an AI Strategy\n\n\n↓\n\n\n\n\n\nYou’ve been tasked with developing an AI strategy for your business …\n\n\n\n\n… and you’ve read about foundation models …\n\n\n\n\n\n\n\n\n\n… and you’ve heard there are software solutions out there …\n\n\n\n\n… that might get you started on that journey.\n\n\n\n\nAs you research the field, it seems that AI tooling is just a subset of Machine Learning tooling.\n\n\n\n\nSoon, you’re overwhelmed.\n\n\n\n\n\n\n\n\n\nSo we’ve put together a blog-series to get you started, instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA foundation model, also known as large X model (LxM),\nis a machine learning or deep learning model that is\ntrained on vast datasets so it can be applied across a\nwide range of use cases.\n\nGenerative AI applications like Large Language Models\nare often examples of foundation models.\n\nBuilding foundation models is often highly resource-intensive,\nwith the most advanced models costing hundreds of millions of\ndollars to cover the expenses of acquiring, curating, and\nprocessing massive datasets, as well as the compute power\nrequired for training.\n\n …\n\nhttps://en.wikipedia.org/wiki/Foundation_model\n\n\n\n\n\n\n\n\nAI Strategy Series\n\n\nThis is a collection of five blog-posts intended to introduce the reader to how they may begin to think about introducing AI or machine learning to their business. It is deliberately not diving into the technologies. Rather, it is a distillation of my own thinking as well as readings from elsewhere that I have found valuable in evolving a better understanding of what’s needed to succeed, ancillary to the tooling and technologies.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFraming an AI Strategy: Where Do You Start?\n\n\n\n\n\n\n\nColum McCoole\n\n\nFeb 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI is Here, But its Business-Applicability may not be Obvious\n\n\n\n\n\n\n\nColum McCoole\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform Engineering for Evolving AI / ML Solutions\n\n\n\n\n\n\n\nColum McCoole\n\n\nFeb 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataOps: Emerging powerful modular tooling\n\n\n\n\n\n\n\nColum McCoole\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs: Key Emerging Components of the AI Tech Stack\n\n\n\n\n\n\n\nColum McCoole\n\n\nMar 7, 2025\n\n\n\n\n\n\n:::\n\nNo matching items\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout Analect\nI have been working at the intersection of finance and technology most of my career. While all my roles in finance involved leveraging technology, I focused on deepening my technical knowledge with my own start-up, Analect, formed in 2012. My motivation at the time, as a financial analyst, was to bring some of the compelling open-source tooling in the scientific community to the finance domain. More recently, my focus has been on cloud-based platform engineering for machine-learning use-cases (MLOps). Direct hands-on experience with these systems is a necessary part of being able to articulate ideas and strategy around how they can be leveraged within a financial services domain but also other industry domains too. Let’s collaborate together."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Stuff I’m Thinking About",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Categories\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n5. LLMs: Key Emerging Components of the AI Tech Stack\n\n\nConvinced of the value LLMs can bring, the challenge becomes how can we securely and reliably get LLMs to perform complex tasks with real-world data.\n\n\n\nai-strategy-series\n\n\nmachine-learning\n\n\nllmops\n\n\n\n\n\n\n\n\n\n7 Mar 2025\n\n\n25 min\n\n\n\n\n\n\n\n\n\n\n\n\n4. DataOps: Emerging powerful modular tooling\n\n\nData Science depends on good data engineering. Data is the differentiating factor in evolving powerful models and a new paradigm of composable data systems are coming to fruition to meet the demands of machine learning-driven businesses\n\n\n\nai-strategy-series\n\n\nmachine-learning\n\n\ndataops\n\n\n\n\n\n\n\n\n\n28 Feb 2025\n\n\n22 min\n\n\n\n\n\n\n\n\n\n\n\n\n3. Platform Engineering for Evolving AI / ML Solutions\n\n\nThe process of extracting business value from AI is complex which is why you want systems in place, namely platforms, that allow for a combination of experimentation and productionisation and for this to work iteratively.\n\n\n\nai-strategy-series\n\n\nmachine-learning\n\n\nplatform\n\n\n\n\n\n\n\n\n\n14 Feb 2025\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\n2. AI is Here, But its Business-Applicability may not be Obvious\n\n\nAI will be transformational for your workforce, but they will need help to embrace it and practice applied AI — where to use it most effectively\n\n\n\nai-strategy-series\n\n\ndigital-transformation\n\n\napplied-ai\n\n\n\n\n\n\n\n\n\n10 Feb 2025\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\n1. Framing an AI Strategy: Where Do You Start?\n\n\nAI, inspite of the hype, needs your attention. But probably more importantly, your understanding … so that you can mold it for your specific needs\n\n\n\nai-strategy-series\n\n\ndata-science\n\n\nmachine-learning\n\n\n\n\n\n\n\n\n\n3 Feb 2025\n\n\n13 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ai-strategy-series/4-dataops-modular-tooling/index.html",
    "href": "posts/ai-strategy-series/4-dataops-modular-tooling/index.html",
    "title": "4. DataOps: Emerging powerful modular tooling",
    "section": "",
    "text": "Key Takeaway\n\n\n\n\n\nAlthough many data scientists are eager to build and tune ML models, the reality is an estimated 70% to 80% of their time is spent toiling in the bottom three parts of the hierarchy — gathering data, cleaning data, processing data.\nMaking it easy for your team to work with a curated set of data, by combining modular components of modern data-stack, will ease the iterative process of experimentation and allow for productionisation of workflows that scale more easily.\n\n\n\n\n\n\n\n\nFigure 1: Data Science Hierarchy of Needs1\n\n\n\n\n\nWe are in a sweet-spot in terms of being able to harvest the fruits of years of effort from various opensource projects directed at making working with data at scale more efficient and less dependent on proprietary solutions. For those locked into vendors, it’s perhaps time to dispense with those relationships and avail of this new generation of performant tools."
  },
  {
    "objectID": "posts/ai-strategy-series/4-dataops-modular-tooling/index.html#footnotes",
    "href": "posts/ai-strategy-series/4-dataops-modular-tooling/index.html#footnotes",
    "title": "4. DataOps: Emerging powerful modular tooling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe AI Hierarchy of Needs, Monica Rogati, June 2017.↩︎\n2024 Gartner Market Guide to DataOps, DataKitchen Marketing Team, Aug. 2024↩︎\nNine dimensions for assessing data quality: Rewired, The McKinsey Guide to Outcompeting in the Age of Digital and AI, Wiley, June 2023.↩︎\nThe Road to Composable Data Systems:, Thoughts on the Last 15 Years and the Future, Wes McKinney, September 2023↩︎\nThe Composable Data Management System Manifesto, Proceedings of the VLDB (very large database) Endowment, Volume 16 No. 10, Pedro Pedreira et al., June 2023↩︎\nGPU-powered data science enables much greater interactivity, but affords fewer coffee breaks, Shashank Prasanna & Mark Harris, NVIDIA, Oct. 2018↩︎\nA composable data system, with 3 key standards: Open standards over silos, Chapter 1, Open Standards, The Composable Codex, Voltron Data, 2023↩︎\nIbis is a composable UI that can interoperate with multiple execution engines and data storage layers.: Bridging divides: Language interoperability, Chapter 2, Language Interoperability, The Composable Codex, Voltron Data, 2023↩︎\nCode flows from the user through the UI, which then passes the IR (intermediate representation) plan to the engine for execution: Bridging divides: Language interoperability, Chapter 2, Language Interoperability, The Composable Codex, Voltron Data, 2023↩︎\n Comparison of the three connectivity approaches: From data sprawl to data connectivity, Chapter 3, Data Connectivity, The Composable Codex, Voltron Data, 2023↩︎\nThe advent of the Open Data Lake:, Julien Le Dem, Nov. 2024↩︎\nThe advent of the Open Data Lake:, Julien Le Dem, Nov. 2024↩︎\nLakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics, Michael Armbrust et al., Jan. 2021.↩︎\nThe Data Quarry: Series on Embedded Databases, Prashant Rao, 2023↩︎\nThe Road to Composable Data Systems:,Thoughts on the Last 15 Years and the Future, Wes McKinney, September 2023↩︎\nDuckDB Doesn’t Need Data To Be a Database, Nikolas Gobel, May 2024↩︎\nSample DuckDB-centric data pipeline enabled by DuckDB from DuckDB Beyond the Hype, Alireza Sadeghi, Sept. 2024.↩︎\nDAGWork’s 5-layer modular data-stack from Hamilton & Kedro for modular data pipelines, DAGWorks, Mar. 2024.↩︎\nData-Centric AI vs. Model-Centric AI MIT Lecture series, 2024↩︎\nFoundations for a Multi-Modal Lakehouse for AI, Data Council Technical Talk, April 2024↩︎"
  },
  {
    "objectID": "posts/ai-strategy-series/5-llm-apps-llmops/index.html",
    "href": "posts/ai-strategy-series/5-llm-apps-llmops/index.html",
    "title": "5. LLMs: Key Emerging Components of the AI Tech Stack",
    "section": "",
    "text": "Key Takeaway\n\n\n\nLLMs have become progressively more capable and exponentially cheaper over the past two years. While they need careful curation when deployed as part of an overall business solution, LLMs have the potential to bring significant value to a business.\nUnlike traditional ML models, which operate on structured data, LLMs handle the vast and often messy world of text and code. This introduces a new layer of complexity, which demands special techniques for data ingestion, pre-processing, and training.\nLLMOps is about production monitoring and continual improvement, linked by evaluation. The better your evals, the faster you can iterate on experiments, and thus the faster you can converge on the best version of your system."
  },
  {
    "objectID": "posts/ai-strategy-series/5-llm-apps-llmops/index.html#footnotes",
    "href": "posts/ai-strategy-series/5-llm-apps-llmops/index.html#footnotes",
    "title": "5. LLMs: Key Emerging Components of the AI Tech Stack",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSimon Willison’s content tagged with ‘llm’↩︎\nWhat’s new in the world of LLMs, for NICAR 2025, National Institute for Computer-Assisted Reporting, 8 March 2025↩︎\n18 labs put out a GPT-4 equivalent model in 2024: Google, OpenAI, Alibaba (Qwen), Anthropic, Meta, Reka AI, O1 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton & Tencent (source: Simon Willison)↩︎\nLLM inference cost is going down fast, from: Welcome to LLMflation, Guido Appenzeller, a16z, Nov. 2024↩︎\nLLM Leaderboard from: artificialanalysis.ai, Comparison of GPT-4o, Llama 3, Mistral, Gemini and over 30 models↩︎\nOn DeepSeek and Export Controls, Dario Amodei, January 2025↩︎\nMixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.↩︎\nDeepSeek-V3 Technical Report, DeepSeek-AI, Dec. 26, 2024↩︎\nDeepSeek, Reasoning Models, and the Future of LLMs, a16z partners Guido Appenzeller and Marco Mascorro, discussing reasoning models, 5 March 2025↩︎\nStructured data extraction using LLM, Simon Willison, Nicar25 Scraping Workshop, March 2025↩︎\nRetrieval-augmented generation (RAG) is fundamental in most generative AI applications. RAG’s core responsibility is to inject custom data into the large language model (LLM) to perform a given action (e.g., summarize, reformulate, and extract the injected data). You often want to use the LLM on data it wasn’t trained on (e.g., private or new data). As fine-tuning an LLM is a highly costly operation, RAG is a compelling strategy that bypasses the need for constant fine-tuning to access that new data.↩︎\nChapter 11 - MLOps and LLMOps, LLM Engineer’s Handbook, Paul Iusztin & Maxime Labonne, Packt Publishing, Oct. 2024↩︎\nOperationalization journey per generative AI user type: from FMOps/LLMOps: Operationalize generative AI and differences with MLOps, Sokratis Kartakis and Heiko Hotz, AWS, Sept. 2023.↩︎\nFrom RAG to fabric: Lessons learned from building real-world RAGs at GenAIIC – Part 1, AWS Machine Learning Blog, Oct. 2024↩︎\nAchieve operational excellence with well-architected generative AI solutions using Amazon Bedrock, AWS Machine Learning Blog, Oct. 2024↩︎\nBeyond MLOps: Building AI systems with Metaflow, Ville Tuulos of Outerbounds presenting at Data Council, April 2024.↩︎\nBuilding AI Systems with Metaflow slide-deck, Ville Tuulos, Outerbounds, April 2024↩︎\nAn ML/AI-driven company of 2026 from: Building AI Systems with Metaflow slide-deck, Ville Tuulos, Outerbounds, April 2024.↩︎\nMy LLM codegen workflow atm, by Harper Reed, 16 Feb. 2025↩︎\nChapter 11 - MLOps and LLMOps, LLM Engineer’s Handbook, Paul Iusztin & Maxime Labonne, Packt Publishing, Oct. 2024↩︎\nWhat We’ve Learned From A Year of Building with LLMs, June 2024↩︎\nLessons From A Year Building With LLMs, AI Engineer conference, July 2024↩︎\nAchieve operational excellence with well-architected generative AI solutions using Amazon Bedrock, Akarsha Sehwag, Zorina Alliata, Malcolm Orr, and Tanvi Singhal, AWS, Oct. 2024.↩︎\nHamel Husain blog on matters pertaining to LLMs at https://hamel.dev/↩︎\nLooking at Data: Your Secret Weapon, Hamel Husain, Jan. 2025↩︎\nHow to Construct Domain Specific LLM Evaluation Systems: Hamel Husain and Emil Sedgh, Rechat development of Lucy, an AI personal assistant designed to support real estate agents.↩︎\nHow To Systematically Improve The AI from: Your AI Product Needs Evals, How to construct domain-specific LLM evaluation systems, Hamel Husain, March 2024.↩︎\nHow Clearwater Analytics is revolutionizing investment management with generative AI and Amazon SageMaker JumpStart AWS Machine Learning Blog, Dec. 2024↩︎\nA Cutting-Edge Framework for Evaluating LLM Output, Clearwater Analytics Engineering, Aug. 2024↩︎\nOperationalize LLM Evaluation at Scale using Amazon SageMaker Clarify and MLOps services, Sokratis Kartakis, Jagdeep Singh Soni, and Riccardo Gatti, AWS, Nov. 2023.↩︎"
  }
]